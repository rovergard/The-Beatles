{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                                      int64\n",
       "SongKey                                object\n",
       "song                                   object\n",
       "songwriters                            object\n",
       "lead_vocals                            object\n",
       "year                                    int32\n",
       "cover                                   int64\n",
       "Era                                    object\n",
       "first_release_date             datetime64[ns]\n",
       "max_key                               float64\n",
       "mode                                  float64\n",
       "avg_danceability                      float64\n",
       "avg_energy                            float64\n",
       "avg_loudness                          float64\n",
       "avg_speechiness                       float64\n",
       "avg_acousticness                      float64\n",
       "avg_instrumentalness                  float64\n",
       "avg_liveness                          float64\n",
       "avg_valence                           float64\n",
       "avg_tempo                             float64\n",
       "avg_duration_ms                       float64\n",
       "avg_time_signature                    float64\n",
       "Song_y                                 object\n",
       "lyrics                                 object\n",
       "avg_popularity                        float64\n",
       "core_catalogue_releases                object\n",
       "Canonical_album                        object\n",
       "first_vocalist                         object\n",
       "Paul_Song                               int32\n",
       "John_Song                               int32\n",
       "George_Song                             int32\n",
       "Ringo_Song                              int32\n",
       "popularity                              int32\n",
       "BB_name                                object\n",
       "BB_artist                              object\n",
       "BB_debut_date                  datetime64[ns]\n",
       "BB_peak_position                        Int64\n",
       "BB_peak_date                   datetime64[ns]\n",
       "BB_weeks_on_chart                       Int64\n",
       "RollingStonePosition                  float64\n",
       "RobSegment                              int64\n",
       "LauraSegment                            int64\n",
       "EmilySegment                            int64\n",
       "OliviaSegment                           int64\n",
       "BrianSegment                            int64\n",
       "JackieSegment                         float64\n",
       "vader_neg                             float64\n",
       "vader_neu                             float64\n",
       "vader_pos                             float64\n",
       "vader_compound                        float64\n",
       "roberta_neg                           float64\n",
       "roberta_neu                           float64\n",
       "roberta_pos                           float64\n",
       "Pipeline_sentiment_label               object\n",
       "Pipeline_sentiment_score              float64\n",
       "distilbertsentiment                     int64\n",
       "FinetunedSentiment_Negative             uint8\n",
       "FinetunedSentiment_Positive             uint8\n",
       "cluster                                 int32\n",
       "Cluster_Name                           object\n",
       "keyname                                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('BeatlesSongsClustered.pkl')\n",
    "\n",
    "##These facts are sorted in alphabetical order. To elminiate any potiential bias, I will shuffle the order of the facts\n",
    "\n",
    "#I know I don't have to do this, but I'm going to do it anyway. old instincts when we had to do all of this without fancy libraries\n",
    "\n",
    "df['random'] = np.random.rand(len(df))\n",
    "df.sort_values('random', inplace=True)\n",
    "df.drop('random', axis=1, inplace=True)\n",
    "\n",
    "# Reset the index\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df.dtypes\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Selecting only numeric features\n",
    "num_features = ['year', 'avg_danceability', 'avg_energy', 'avg_loudness', 'avg_speechiness', \n",
    "                'avg_acousticness', 'avg_instrumentalness', 'avg_liveness', 'avg_valence', \n",
    "                'avg_tempo', 'avg_duration_ms', 'avg_time_signature', 'avg_popularity'\n",
    "                ]\n",
    "\n",
    "\n",
    "cat_features = ['Era', 'mode', 'keyname', 'Cluster_Name']\n",
    "                \n",
    "\n",
    "##This is just a handy reference or could be useful if I want to do some more feature engineering\n",
    "excluded_features = ['Id', 'SongKey', 'song', 'songwriters', 'lead_vocals', 'cover',\n",
    "                     'first_release_date', 'max_key', 'Song_y', 'lyrics', \n",
    "                     'core_catalogue_releases', 'Canonical_album', 'first_vocalist',\n",
    "                     ###'Paul_Song', \n",
    "                     'John_Song', 'George_Song', 'Ringo_Song', 'popularity', \n",
    "                     'BB_name', 'BB_artist', 'BB_debut_date', 'BB_peak_date', \n",
    "                     'distilbertsentiment', 'FinetunedSentiment_Negative', \n",
    "                     'FinetunedSentiment_Positive', 'cluster', 'vader_neg', 'vader_neu',\n",
    "                     'vader_pos', 'vader_compound', 'roberta_neg', 'roberta_neu', \n",
    "                     'roberta_pos', 'Pipeline_sentiment_label', 'Pipeline_sentiment_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.625\n",
      "Confusion Matrix: [[20  8]\n",
      " [ 7  5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rob\\AppData\\Local\\Temp\\ipykernel_20420\\1446395236.py:20: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  df = df.fillna(df.median())\n",
      "C:\\Users\\rob\\AppData\\Local\\Temp\\ipykernel_20420\\1446395236.py:20: FutureWarning: The default value of numeric_only in DataFrame.median is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  df = df.fillna(df.median())\n"
     ]
    }
   ],
   "source": [
    "## Try Decision Tree Classifier\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Define Preprocessing for numeric columns (scale them)\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# Define Preprocessing for categorical columns (encode them)\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))])  # We use OneHotEncoder here\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_features),\n",
    "        ('cat', categorical_transformer, cat_features)])\n",
    "\n",
    "# Fill missing values with the median of the column\n",
    "df = df.fillna(df.median())\n",
    "\n",
    "# Split data into features and target variable\n",
    "X = df.drop(columns='Paul_Song')\n",
    "y = df['Paul_Song']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Create a pipeline that does the preprocessing and then fits the classifier\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', DecisionTreeClassifier())])\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Model Accuracy\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred))\n",
    "\n",
    "#Confusion Matrix\n",
    "print(\"Confusion Matrix:\",confusion_matrix(y_test, y_pred))\n",
    "\n",
    "\n",
    "##Accuracy: 0.5\n",
    "##Confusion \n",
    "# Matrix: [[15  9]\n",
    "#          [11  5]]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not a good canidate for tree classification because it won't generalize. Overfitting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n",
      "Confusion Matrix: [[27  1]\n",
      " [ 9  3]]\n",
      "Precision: 0.75\n",
      "Recall: 0.25\n",
      "F1 Score: 0.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rob\\AppData\\Local\\Temp\\ipykernel_20420\\1383498590.py:18: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  df = df.fillna(df.median())\n",
      "C:\\Users\\rob\\AppData\\Local\\Temp\\ipykernel_20420\\1383498590.py:18: FutureWarning: The default value of numeric_only in DataFrame.median is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  df = df.fillna(df.median())\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define Preprocessing for numeric columns (scale them)\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# Define Preprocessing for categorical columns (encode them)\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))])  # We use OneHotEncoder here\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_features),\n",
    "        ('cat', categorical_transformer, cat_features)])\n",
    "\n",
    "# Fill missing values with the median of the column\n",
    "df = df.fillna(df.median())\n",
    "\n",
    "# Split data into features and target variable\n",
    "X = df.drop(columns='Paul_Song')\n",
    "y = df['Paul_Song']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Create a pipeline that does the preprocessing and then fits the classifier\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', RandomForestClassifier())]) # We use RandomForestClassifier here\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Model Accuracy\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred))\n",
    "\n",
    "#Confusion Matrix\n",
    "print(\"Confusion Matrix:\",confusion_matrix(y_test, y_pred))\n",
    "# Precision, Recall, F1 Score\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Precision: {:.2f}\".format(precision))\n",
    "print(\"Recall: {:.2f}\".format(recall))\n",
    "print(\"F1 Score: {:.2f}\".format(f1))\n",
    "\n",
    "\n",
    "\n",
    "## Accuracy: 0.775\n",
    "## Confusion Matrix: [[28  0]\n",
    " #                    [ 9  3]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                feature  importance\n",
      "5                      avg_acousticness    0.113039\n",
      "1                      avg_danceability    0.090280\n",
      "2                            avg_energy    0.080349\n",
      "4                       avg_speechiness    0.072814\n",
      "7                          avg_liveness    0.068528\n",
      "12                       avg_popularity    0.065799\n",
      "10                      avg_duration_ms    0.062332\n",
      "8                           avg_valence    0.057789\n",
      "6                  avg_instrumentalness    0.056696\n",
      "3                          avg_loudness    0.054504\n",
      "9                             avg_tempo    0.054486\n",
      "0                                  year    0.042008\n",
      "26                            keyname_F    0.024341\n",
      "11                   avg_time_signature    0.015815\n",
      "13                      Era_Beatlemania    0.010811\n",
      "31                  Cluster_Name_Angsty    0.010142\n",
      "28                            keyname_G    0.009910\n",
      "18                            keyname_A    0.009424\n",
      "33    Cluster_Name_Eclectic Experiments    0.009028\n",
      "21                            keyname_C    0.008358\n",
      "34                Cluster_Name_Fab Four    0.008114\n",
      "23                            keyname_D    0.007857\n",
      "14                     Era_Experimental    0.007647\n",
      "25                            keyname_E    0.007501\n",
      "36  Cluster_Name_Psychedelic Soundscape    0.006247\n",
      "30         Cluster_Name_Acoustic Beauty    0.006035\n",
      "22                        keyname_C#/Db    0.005409\n",
      "27                        keyname_F#/Gb    0.005231\n",
      "32            Cluster_Name_Early Covers    0.005085\n",
      "20                            keyname_B    0.004614\n",
      "15            Era_Group of Solo Artists    0.004249\n",
      "16                             mode_0.0    0.003994\n",
      "29                        keyname_G#/Ab    0.003108\n",
      "19                        keyname_A#/Bb    0.003079\n",
      "17                             mode_1.0    0.003075\n",
      "35         Cluster_Name_Magical Musings    0.001723\n",
      "24                        keyname_D#/Eb    0.000582\n"
     ]
    }
   ],
   "source": [
    "# Get feature importances\n",
    "importances = clf.named_steps['classifier'].feature_importances_\n",
    "\n",
    "# Get feature names\n",
    "num_features_names = num_features\n",
    "cat_features_names = clf.named_steps['preprocessor'].transformers_[1][1]\\\n",
    "   .named_steps['encoder'].get_feature_names_out(cat_features)\n",
    "\n",
    "features_names = np.concatenate([num_features_names, cat_features_names])\n",
    "\n",
    "# Now that you have the importances and corresponding feature names,\n",
    "# you can sort the features by importance\n",
    "\n",
    "feature_importances = pd.DataFrame({'feature': features_names, 'importance': importances})\n",
    "feature_importances.sort_values(by='importance', ascending=False, inplace=True)\n",
    "\n",
    "print(feature_importances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
